\chapter{ The Problem of Pattern Prediction and the Proposed Approach }

\label{chapter:system}

\par In this chapter, we introduce our proposed approach for pattern prediction over multiple input event streams. We start by defining the problem that we address in this thesis, which is divided into two parts: the formal definition of the pattern prediction over an individual event stream, then it is extended to the case of multiple streams. We present the used base model for event pattern prediction, and our proposed approach to leverage the distributed online protocol to enable knowledge sharing between prediction models over multiple event streams. Furthermore, we provide an analysis of the theoretical aspects of the proposed approach.

\par We follow the general notation and terminology of \cite{agrawal2008efficient,schultz2009distributed,luckham2008power,alevizos2015complex,zhou_pattern_2015,kamp2014communication} to formalize the problem we tackle and our solution approach.


\section{Pattern Prediction over a Single Event Stream}


\par In this section, we define the first part of the problem that we tackle in this thesis, by defining the problem of pattern prediction over a single event stream. We also give an introduction of the base prediction model, which is built based on the event forecasting with pattern Markov chains method \cite{alevizos2017event}.


\subsection{Basic Problem Formulation}

We first define the input event and the stream of events as follows:  
\begin{definition}
	Each event is defined as a tuple of attributes denoted by $e_i$, where 
	$e_i = (id,type,\tau,a_1,a_2,\ldots,a_n)$, $type\in\Sigma$ is the event type attribute that takes a value from a set of finite event types/symbols $\Sigma$, $\tau\in\R$ represents the time when the event tuple was created,  the  $a_1,a_2,...,a_n$ are spatial or other contextual features (e.g., speed); these features vary from one application domain to another. The attribute $id\in\N$ is a unique identifier that connects the event tuple to an associated domain object.
\end{definition}

\begin{definition}
A stream $s=\langle e_1,e_3,...,e_t,...\rangle$  is a time-ordered sequence of events.
\end{definition}


\par A user-defined pattern $\mathcal{P}$ is given in the form of a regular expression over a set of event types $\Sigma$ (i.e., alphabet). Let a word over $\Sigma$ be a sequence of event types, and the set of words over $\Sigma$ be a language $L$. Then $L(\mathcal{P})$ is the regular language defined by the regular expression ($\mathcal{P}$) \cite{hopcroft2006automata,nuel_pattern_2008,alevizos2017event},  where a regular expression is an event type $\in$ $\Sigma$, or defined using the following operators over regular expressions:
 
\begin{itemize}[noitemsep]
	\item \textit{sequence} that represents a concatenation of two regular expressions languages 
	\item \textit{disjunction} i.e., union, which is the language that its words belong to one of the languages of the two regular expressions 
	\item \textit{iteration} operation to define the set of all possible concatenation over a regular expression
\end{itemize}

More formally, a pattern is given through the following grammar:
\begin{definition}
$\mathcal{P} := E\ |\ \mathcal{P}_{1} ; \mathcal{P}_{2}\ | \mathcal{P}_{1} \vee \mathcal{P}_{2}\ |\ \mathcal{P}_{1}^{*}  $, where $E \in \Sigma$ is a constant event type. $;$ stands for sequence, $\vee$ for disjunction and $*$ for $\mathit{Kleene}-*$.
The pattern $\mathcal{P} := E$ is matched by reading an event $e_i$ iff $e_{i}.type = E$.
The other cases are matched as in standard automata theory.
\end{definition}


The $\mathcal{P}$ (regular expression) is encoded by a deterministic finite automaton (DFA). We define the DFA as following: 

\begin{definition}[\cite{hopcroft2006automata}]
	$(\Sigma,Q,s,F,\delta)$ is a deterministic finite automaton (DFA)  where  $\Sigma$ a finite alphabet of event types, and $Q$ is a finite set of states, $s \in Q$ a start state and $F \subset Q$ represents all final states. $\delta: Q \times \Sigma \rightarrow Q$ is a transition function from a state to another state given an input event type, which is defined as recursive function $\delta(q,e_{1}e_{2}\ldots e_{d})=\delta(\delta(q,e_{1}e_{2}...e_{d-1}),e_{d})$. If $\delta(s,w) \in F$ of a word $w=e_{1}e_{2}\ldots e_{d} \in \Sigma^{*}$, then the word $w$ is said to be accepted by the DFA. In addition,  $\delta(q)^{-m}$ is the set of words of size $m$ defined as $\{w \in \Sigma^{m} \mid \exists q \in Q,\ \delta(p,w)=q \}$
\end{definition}


\par The problem setting can be summarized as follows: given a stream $s$ of low-level events and a pattern $\mathcal{P}$, 
the goal is to estimate at each new event arrival the number of future events
that we will need to wait for until the pattern is completed (full match).

\subsection{Base Prediction Model}
\label{sec:Event-Forecasting-PMC}

\par In this thesis, we use the event forecasting with pattern Markov chains method \cite{alevizos2017event} to construct a pattern prediction model over an event stream. Next, we describe the details of this approach. We first provide an overview of the Patten Markov Chain framework \cite{nuel_pattern_2008}. Then, we describe how this framework is used to build a pattern prediction model \cite{alevizos2017event}.  


\subsubsection*{Pattern Markov Chain (PMC)}

~\citet{alevizos2017event} proposed to employ the Pattern Markov Chain (PMC) \cite{nuel_pattern_2008} to build an online prediction model associated with a pattern over an event stream. The algorithm of constructing a PMC associated with a pattern $\mathcal{P}$ over a stream of events $s$ consists of the following steps:

\begin{itemize}[noitemsep]
	\item Build a DFA that accepts the regular expression $\Sigma^{*};\mathcal{P}$. Firstly, the regular expression $\Sigma^{*};\mathcal{P}$ is converted to non-deterministic finite automaton (NFA), then an equivalent DFA of the constructed NFA is computed using the subset construction \cite{hopcroft2006automata,alevizos2017event}. And the events stream $s$ is considered as the input word of the DFA. 

\par Furthermore, if $\forall q \in Q$ of a DFA the all $\delta(q)^{-m}$ are sets of cardinality 1, then the DFA is called \textit{m-unambiguous}. ~\citet{nuel_pattern_2008} proposed a procedure to transform any DFA to an \textit{m-unambiguous} DFA, which is achieved by incrementally duplicate all states have m-ambiguity (i.e., $\vert\delta(q)^{-m}\vert > 1$).   Figure ~\ref{fig:dfa_adc} shows an associated DFA of a sequential pattern $\mathcal{P}=a ; d ; c$ over an alphabet $\Sigma=\{a,b,c,d\}$. 


\input{dfa_figure}

%(note that the DFA has no dead states since we need to handle streams and not strings).

\item  Given a constructed \textit{m-unambiguous} DFA for the pattern $\mathcal{P}$, and  assuming that the input events stream $s=\langle e_1,e_3,...,e_t,...\rangle$ is a $m$-order homogeneous Markov sequence, where $m \geq 1$.  ~\citet{nuel_pattern_2008} showed that the sequence of states of the DFA that generated by consuming the input events stream $s$ is a first-order homogeneous Markov chain, which is represented by $\langle q_{0},q_{1},...,q_{t},...\rangle$, where $q_{0}=s$ and $q_{t}=\delta(q_{t-1},e_{t})$. We denote by \pmcmr the derived Markov chain associated with a pattern $\mathcal{P}$ that is called a Pattern Markov Chain (PMC) of order $m$ \cite{nuel_pattern_2008}. In other words, we perform a direct mapping of the states of the DFA to states of a homogeneous Markov chain and the transitions of the DFA to transitions of the Markov chain. Thus, the terms \textit{m-unambiguous} DFA of a pattern and the corresponding \pmcmr  will be used interchangeably. 

\par Furthermore, the \pmcmr model is characterized by a $\vert Q \vert \times \vert Q \vert$ transition probability matrix $\Pi$ where $Q$ is the set of states of the  \textit{m-unambiguous} DFA. Figure ~\ref{fig:pmc} depicts the PMC of order 1 for the generated DFA of Figure ~\ref{fig:dfa_adc}.

%\par The next step is to derive a Markov chain that will be able to provide a probabilistic description of the DFA's run-time behavior.
%\par Towards this goal, we use Pattern Markov Chains, as was proposed in \cite{nuel_pattern_2008}.
%, it can be shown that there is a direct mapping of the states of the DFA to states of a Markov chain and the transitions of the DFA to transitions of the Markov chain.
%\par The transition probabilities of the Markov chain are the occurrence probabilities of the various event types.
%On the other hand, if the occurrence probabilities of the events are dependent on some of the previous events  seen in the stream (i.e., the stream is generated by an $m^{th}$ order Markov process), we might need to perform a more complex transformation 
%(see \cite{nuel_pattern_2008} for details)
%in order to obtain a ``proper'' Markov chain.
%The transition probabilities are then conditional probabilities on the event types.
%In any case,
%we call such a derived Markov chain a Pattern Markov Chain (PMC) of order $m$
%and denote by \pmcmr , where $\mathcal{P}$ is the initial pattern and $m$ the assumed order.
 
\end{itemize}


\input{dfa_mc_figure}
%\end{comment}

\subsubsection*{Constructing the Pattern Prediction Model}
\label{sec:pmc_prediction}

~\citet{alevizos2017event} proposed to use the constructed \pmcmr to build a probabilistic prediction model that describes the DFA's run-time behavior. The method is based on calculating the \textit{waiting-time} distributions. Given a specific state of the \pmcmr, a \textit{waiting-time} distribution provides the probability of reaching an absorbing state in $n$ transitions from the current state. So by mapping the final states of the DFA to absorbing states of the \pmcmr by adding self-loops with probabilities equal to $1.0$. Therefore, we can calculate the probability of reaching a final state in $n$ transitions, which means predicting a full match of the defined pattern $\mathcal{P}$.

\par We denote by $W_{\mathcal{P}}(q)$ the waiting-time random variable that represents the number of transitions from a current state $q$ of DFA to reach a final state \cite{alevizos2017event}, where it also represents the expected number of future events from the current time event to a full match of the pattern $\mathcal{P}$, which is given by 

\begin{equation*}
W_{\mathcal{P}}(q)=inf\{n: q_{0},q_{1},...,q_{n}, q_{0}=q, q \in Q \backslash F, q_{n} \in F\}
\end{equation*}

where $Q$ is the set of states of the DFA, and $F$ the set of the  all final states. However, the \textit{waiting-time} distribution of the $W_{\mathcal{P}}(q)$ random variable can be computed based on the transition probability matrix $\Pi$ of the \pmcmr, where it has $h$ non-final states and $d$ final states (absorbing states) \cite{alevizos2017event}, then the distribution is calculated by the following equation 

\begin{equation*}
P(W_{\mathcal{P}}(q)=n)=\boldsymbol{\xi_{q}}\boldsymbol{N}^{n-1}(\boldsymbol{I}-\boldsymbol{N})\boldsymbol{1}
\end{equation*}
where $\boldsymbol{N}$ is $h \times h$ matrix that obtained by re-arranging the transition matrix $\Pi$ to include transitions between the non-final states of the DFA, $\boldsymbol{I}$ is an identity matrix of size $h \times h$, and  $\boldsymbol{1}$ is a $h$-dimensional vector of ones. The $\boldsymbol{\xi_{q}}$ is $1 \times h$ row of elements that contains zeros except $1.0$ in the cell corresponding to $q$. 
\par Finally, the model provides the prediction reports in the form of intervals i.e.,  $I=(\mathit{start},\mathit{end})$. Which means that the DFA is expected to reach a final state  after future transitions (number of events $n$) between $\mathit{start}$ and $\mathit{end}$ with probability $P(I)$ at least some constant threshold $\theta_{p}$ that defined by the user, given by:
\begin{equation*}
P(I)=\sum_{n \in I}{P(W_{\mathcal{P}}(q)=n)}\ where\  P(I) \geq \theta_{p} 
\end{equation*}
where $P(I)$ equals the sum of probabilities of all number of future events $n$ that fall within $I$ ($start\leq n\leq end$). Furthermore, the length of the intervals ($spread(I) = end - start$)  can be restricted to not be greater than a maximum spread threshold $\theta_{s}$ ($spread(I)\leq \theta_{s}$)



\begin{figure}[H]
	\begin{centering}
		\center
		\includegraphics[width=\textwidth,keepaspectratio]{chapters/figures/new_wt.png}
		
		
		\caption{Waiting-time distribution for
			$\mathcal{P}=a ; d ; c$, $\Sigma=\{a,b,c,d\}$, $m=1$, $\theta_{p}=0.5\ and\ \theta_{s}=20$.}
		\label{fig:wt1}
	\end{centering}
\end{figure}

\par These intervals are estimated by a single-pass algorithm that scans a waiting-time distribution and finds the smallest (in terms of length) interval that exceeds the $\theta_{p}$ and has a spread  not greater that $\theta_{s}$. For example, Figure~\ref{fig:wt1} shows the \textit{waiting-time} distributions for all non-final states of the DFA presented in Figure~\ref{fig:wt1}, and the generated intervals are depicted in Figure~\ref{fig:predictionsIntervals}.


\begin{figure}[H]
	\begin{centering}
		\center
			\includegraphics[width=\textwidth,keepaspectratio]{chapters/figures/new_prediction_intervals.png}
					
		\caption{Example of the computed prediction intervals for
			$\mathcal{P}=a ; d ; c$, $\Sigma=\{a,b,c,d\}$, $m=1$, $\theta_{p}=0.5\ and\ \theta_{s}=20$.}
		\label{fig:predictionsIntervals}
	\end{centering}
\end{figure}

\par The proposed method assumes that the transition probability matrix $\Pi$ is available to build the prediction intervals. However, this is not true in the real-world applications.
Therefore, it is essential to learn the values of the \pmcmr's transition probability matrix in order apply this method. One common way, is to use the maximum-likelihood estimator to learn the transition probabilities as illustrated in Section ~\ref{sec:theoretical}. 

\par This model is performing the learning over an event stream $s$, which is usually has a slow convergence to a sufficiently good model. Where in the case of multiple event streams, a unique model associated with each stream is needed. Accordingly, we present in this work, a technique to share information among the \pmcmr predictors over multiple input event streams (i.e., distributed learning of the transition probability matrix).

\section{Pattern Prediction over Multiple Event Streams}

We extend the pattern prediction problem over a single event stream to the case of multiple distributed input event streams, where there is an associated prediction model for each event stream. We further present our proposed cooperative learning based approach by using a distributed online prediction protocol \cite{kamp2014communication} to synchronize the distributed prediction models in a communication-efficient manner. 


\subsection{Extended Problem Formulation}

\par In this section, we extend the problem of pattern prediction over a single event stream to consider the setting where there are multiple input event streams. Let $O = \{ o_1, ..., o_k\}$ be a set of \emph{$K$} objects/entities (e.g., moving objects), each of which is generating an event stream $s_i$, hence, we have a set of real-time input event streams $S = \{ s_1, ..., s_k\}$, where these streams are produced independently from the same distribution.


 \par $\mathcal{P}$ is a user-defined pattern given in the form of regular expression, which is monitored in every stream $s_i \in S$. Then, we have a system consists of \emph{$K$} local predictor (learner) nodes $n_1,n_2\dots,n_k$, each of which receives an input event stream $s_i\in S$ that is associated with a single object $o_i \in O$.

\par  The goal is to provide online predictions about the completion of the pattern $\mathcal{P}$ within each stream $s_i$. Each node maintains a local prediction model $f_i$. Then for each new arriving event tuple  $e_t \in s_i$, the $f_i$ model provides an online prediction interval about the future full match of the pattern $\mathcal{P}$.

\par In other words, we have separated running instances of an online prediction algorithm on distributed nodes for \emph{$K$} input event streams. For example, massive streams of events that describe trajectories of group of moving vessels in the context of maritime monitoring, where there is one predictor node for each vessel's event stream.
  
  
  \par In this work, we employ the \pmcmr models on the distributed predictor nodes, each model is associated with a particular event stream. While these predictors can work in isolation with no communication with other local predictors, such non-cooperative way leads to inefficiency in terms of learning convergence and predictive performance among all predictors. Thus, in this work, we propose to use the distributed online prediction protocol \cite{kamp2014communication} to enable the communication among the local predictors to synchronize their models.     
%
%The defined pattern $\mathcal{P}$ is monitored over each event stream $s_i$  by a  predictor nodes  $n_i$  that maintains a local prediction model $f_i$, where there is one node for each vessel's event stream.  The prediction model $f_i$ gives the ability to provide an online predictions about when the pattern will be completed in the form of an expected number of future events before a full match does occur.

\subsection{The Proposed Method}
\label{sec:proposed_approach}

\par This work proposes a scalable and distributed prediction system for user-defined patterns over multiple massive input event streams. The system  uses the PMC forecasting method \cite{alevizos2017event} as the base prediction model, where there is a \pmcmr model associated with each input event stream $s_i$ on a predictor node $n_i$. And it employs the distributed online learning protocol \cite{kamp2014communication} to exchange information among the distributed predictors of the input event streams, which allows to synchronize the parameters of their prediction models, which are represented by the transition matrices.

%
%Thus, the prediction model $f_i$ on a predictor node is represented by \pmcmr and its associated DFA.

\subsection*{Distributed Online Learning for Pattern Prediction}

\par In what follows, we describe the details of adapting the distributed online learning protocol \cite{kamp2014communication} with the pattern prediction (\pmcmr) models. This protocol provides a communication-efficient dynamic synchronization scheme based on a periodic static scheme.


\par Algorithm~\ref{algonline:dol} presents the distributed online prediction protocol by dynamic model synchronization on both the predictor nodes and the coordinator. We refer to the PMC's transition matrix $\boldsymbol{\Pi}_i$ on predictor node $n_i$ by $w_i$, which represents the parameters of the local prediction model $f_i$. 

\par That is, when a predictor $n_i:\ i \in[k]$ observes an event $e_j$ it revises its internal model state ($w_i$) and provides a prediction report. Then it checks the local conditions, by checking the local model divergence from a reference model $w_r$ after consuming a predefined number of events (batch size $b$), to decide whether there is a need to synchronize its local model with the coordinator [or not]. $w_r$ is maintained in the predictor node as a copy of the last computed aggregated model $\hat{w}$ from the previous full synchronization step, which is shared among all distributed predictors.
%define delta%
 \par Let $\Delta$ be a predefined divergence threshold parameter. Then, by monitoring the local condition $(\|w_i - w_r\|^2 > \Delta)$ on all local predictors, we have a guarantee that if none of the local conditions is violated, the divergence (i.e., variance of local models $\delta(w)=\frac{1}{k} \sum_{j=1}^{k}\|w_i - \hat{w}\|^2$) does not exceed the threshold $\Delta$ \cite{kamp2014communication}. This is the key point of this protocol that reduces the communication overhead in comparison to the static based communication scheme, where the predictors always communicate periodically after observing a fixed number ($b$) of events ~\cite{dekel2012optimal}.  

\par On the other hand, the coordinator receives the parameters of prediction models from the predictor nodes that requested for model synchronization (violation). Then it tries to keep incrementally querying other nodes for their local prediction models until reaching out all nodes have been queried, or the variance of the aggregated parameters $\hat{w}$ that is computed from the already received models is less or equal than the divergence threshold $\Delta$. The coordinator uses a synchronization operation to compute the parameters of a global model  $\hat{w}$. Finally, $\hat{w}$ is sent back to the predictor nodes that sent their models after the violation or have been queried by the coordinator. 

\begin{algorithm}[h]
	\caption{Communication-efficient Distributed Online Learning \cite{kamp2014communication}.} 
	\begin{algorithmic}[1] 
		
		\Statex \Indm  \textbf{Predictors:}
		\Statex \Indp node $n_i$: at observing event $e_j$
		
		\Statex \Indp update the parameters of the local prediction model $w_i$ and provide a prediction interval $I$ \;
	 

		\Statex \If {$j\mod b = 0\ and\ \|w_i - w_r\|^2 > \Delta$}  
		\Statex send  $w_i$ to the Coordinator (violation) \;
		\Statex \Indm \textbf{Coordinator}:
		\Statex \Indp receive parameters of local models with violation 
		 $B=\{w_i\}_{i=1}^m$ \;
	
	
		\Statex \While{$|B| \neq k $ and $\frac{1}{|B|} \ \sum_{w_i\in  \Pi}\|w_i - \hat{w}\|^2 > \Delta$}{
			
			 \Statex  \hspace{\algorithmicindent} add other nodes that have not reported violation for \Statex \hspace{\algorithmicindent} their models $ B \gets \{w_l : w_l \notin B\ and\ l \in [k]\}$    \;
			\Statex  \hspace{\algorithmicindent} receive models from nodes in $B$\;
	}
        \Statex
		\Statex compute a new global model $\hat{w}$ \;
		\Statex send $\hat{w}$ to all the predictors in $B$ and set $w_{1}\dots w_{m}=\hat{w} $\; 
		\Statex \If {$|B| = k$}{
		\Statex  \hspace{\algorithmicindent} set a new reference model $w_r	\gets \hat{w}$ \; }
	
	\end{algorithmic}
	\label{algonline:dol}
\end{algorithm}


\par  We use this protocol for the pattern prediction models, which are internally based on the \pmcmr. This allows the distributed \pmcmr predictors for multiple event streams to synchronize their models (i.e., the transition probability matrix of each predictor), and learn a shared model in a communication-efficient way. 


\subsection*{Learning a Global Transition Probability Matrix}

\par We propose a \textit{synchronization operation} for the transition probability matrices ($w_i=\boldsymbol{\Pi}_i :i \in[k]$) of the $k$ distributed \pmcmr predictors. The operation is based on distributing the maximum-likelihood estimation \cite{anderson1957statistical} for the transition probabilities of the \pmcmr models. 
Let $\pi_{i,j}$ the transition probability from state $i$ to state $j$ 
and $n_{k,i,j}$ the number of transitions from state $i$ to state $j$ on node $k$. Then, the global estimation $\hat{\pi}_{i,j}$ for $p_{i,j}$ is described by:

\begin{equation}
\label{eq:dis_pi_estim}
\hat{\pi}_{i,j} = \frac{\sum_{k \in K} n_{k,i,j}}{\sum_{k \in K} \sum_{l \in L} n_{k,i,l}}
\end{equation}

That is,  $\hat{\Pi}$ is the global transition probability matrix that will be shared among all \pmcmr predictors. 
\par Moreover, we measure the divergence of the local models from the reference model $\|w_i - w_r\|^2$ by calculating the sum of square difference between the local transition probability matrix $\Pi_i$ and the reference transition matrix $\Pi_r$:
\begin{equation*}
\label{eq:dis_pi_varinace}
\|w_i - w_r\|^2=|\Pi_i - \Pi_r\|^2=\sum_{l,j} (\pi{i,l,j} -\pi{r,l,j})^2
\end{equation*}

Where $\pi{i,l,j}$ is the transition probability from state $l$ to state $j$ in the $\Pi_i$, and the $\pi{r,l,j}$ the reference transition probability.
\input{chapters/theoretical}


\section{Summary}

\par In this chapter, we addressed the problem of pattern prediction over \emph{$K$} event streams by extending the case of predicting  event patterns over a single stream, where there are \emph{$K$} distributed predictors.  We also described the used prediction model on each predictor, which is based on the event forecasting with pattern Markov chains method \cite{alevizos2017event}. We presented our approach to adapt the distributed online learning protocol \cite{kamp2014communication} that allows the predictors to synchronize their models in a communication-efficient way. Additionally, we provided the theoretical analysis of our approach by deriving a
 probabilistic guarantee on the learning efficiency. 
 
 \par In next chapter, we will introduce the high-level architecture of our pattern prediction system, which is composed of distributed \pmcmr predictors \cite{alevizos2017event} that communicate their models to a coordinator node based a dynamic synchronization scheme \cite{kamp2014communication}. The coordinator computes a global model using the proposed synchronization operation (Equation~\ref{eq:dis_pi_estim}) and shares among the predictors. We will also present the implementation details of the system based on Apache Flink and Apache Kafka.    
 
 