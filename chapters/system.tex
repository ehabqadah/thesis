\chapter{Problem and proposed Approach }

\par This chapter introduces the problem that we address in this thesis, including the formal definition of the pattern prediction over a single event stream and multiple streams. First, we present the base model for events pattern prediction, and our proposed approach to leverage the distributed online protocol to enable knowledge sharing between prediction models over multiple event streams. Furthermore, we provide an analysis of the theoretical efficiency of distributing the learning phase of the pattern prediction models.

\par We follow the general notation and terminology of \cite{agrawal2008efficient,schultz2009distributed,luckham2008power,alevizos2015complex,zhou_pattern_2015,kamp2014communication} to formalize the problem we tackle and our solution approach.

\label{chapter:system}
\section{Pattern Prediction over an Event Stream}


In this section, We first define the problem of predicting the completion of user-defined patterns over a single event stream. Then, we give a brief introduction of the event patterns prediction model over an event stream using the Event Forecasting with Pattern Markov Chains method \cite{alevizos2017event}.


\subsection{Problem Formulation}

We first define the input event and the stream of events as follows:  
\begin{definition}
	Each event is defined as a tuple of attributes $e_i = (id,type,\tau,a_1,a_2.....,a_n)$, where $type$ is the event type attribute that takes a value from a set of finite event types/symbols $\Sigma$, $\tau$ represents the time when the event tuple was created,  the  $a_1,a_2,...,a_n$ are spatial or other contextual features (e.g., speed); these features are varying from one application domain to another. The attribute $id$ is a unique identifier that connects the event tuple to an associated domain object.
\end{definition}

\begin{definition}
A stream $s=\langle e_1,e_3,...,e_t,...\rangle$  is a time-ordered sequence of events.
\end{definition}


\par A user-defined pattern $\mathcal{P}$ is given in the form of a regular expression over a set of event types $\Sigma$ (i.e., alphabet). Let a word over $\Sigma$ be a sequence of event types, and the set of words over $\Sigma$ be a language $L$. Then $L(\mathcal{P})$ is the regular language defined by the regular expression ($\mathcal{P}$) \cite{hopcroft2006automata,nuel_pattern_2008,alevizos2017event},  where a regular expression is an event type $\in$ $\Sigma$, or  defined using the following operators over regular expressions:
 
\begin{itemize}[noitemsep]
	\item \textit{sequence} that represents a concatenation of two regular expressions languages 
	\item \textit{disjunction} i.e., union, which is the language that its words belong to one of the languages of the two regular expressions 
	\item \textit{iteration} operation to define the set of all possible concatenation over a regular expression
\end{itemize}

More formally, a pattern is given through the following grammar:
\begin{definition}
$\mathcal{P} := E\ |\ \mathcal{P}_{1} ; \mathcal{P}_{2}\ | \mathcal{P}_{1} \vee \mathcal{P}_{2}\ |\ \mathcal{P}_{1}^{*}  $, where $E \in \Sigma$ is a constant event type. $;$ stands for sequence, $\vee$ for disjunction and $*$ for $\mathit{Kleene}-*$.
The pattern $\mathcal{P} := E$ is matched by reading an event $e_i$ iff $e_{i}.type = E$.
The other cases are matched as in standard automata theory.
\end{definition}


The problem setting can be summarized as follows: given a stream $s$ of low-level events and a pattern $\mathcal{P}$, 
the goal is to estimate at each new event arrival the number of future events
that we will need to wait for until the pattern is completed (full match).

\subsection{Base Prediction Model}
\label{sec:Event-Forecasting-PMC}

\par In this thesis, we use the Event Forecasting with Pattern Markov Chains method \cite{alevizos2017event} to construct a pattern prediction model over an event stream. In next, we describe the details of this approach. We first provide an overview of the Patten Markov Chain framework \cite{nuel_pattern_2008}. We then describe how this framework is used to build a pattern prediction model \cite{alevizos2017event}.  


\subsubsection*{Pattern Markov Chain (PMC)}

~\citet{alevizos2017event} proposed to employ the Pattern Markov Chain (PMC) \cite{nuel_pattern_2008} to build an online prediction associated with a pattern over an event stream. The algorithm of constructing a PMC associated with a pattern $\mathcal{P}$ over a stream of events $s$ consists of the following steps:

\begin{itemize}[noitemsep]
	\item Build a deterministic finite automata (DFA) that accepts the regular expression $\Sigma^{*};\mathcal{P}$. We define the the DFA as following:
	
	\begin{definition}[\cite{hopcroft2006automata}]
	 $(\Sigma,Q,s,F,\delta)$ is a deterministic finite automaton (DFA)  where  $\Sigma$ a finite alphabet of event types, and $Q$ is a finite set of states, $s \in Q$ a start state and $F \subset Q$ represents all final states. $\delta: Q \times \Sigma \rightarrow Q$ is a transition function from a state to another state given an input event type, which is defined as recursive function $\delta(q,e_{1}e_{2}\ldots e_{d})=\delta(\delta(q,e_{1}e_{2}...e_{d-1}),e_{d})$. If $\delta(s,w) \in F$ of a word $w=e_{1}e_{2}\ldots e_{d} \in \Sigma^{*}$, then the word $w$ is said to be accepted by the DFA. In addition,  $\delta(q)^{-m}$ is the set of words of size $m$ defined as $\{w \in \Sigma^{m} \mid \exists q \in Q,\ \delta(p,w)=q \}$
\end{definition}
	
	First, the regular expression $\Sigma^{*};\mathcal{P}$ is converted to non-deterministic finite automata (NFA), then an equivalent DFA of the constructed NFA is computed using the subset construction \cite{hopcroft2006automata,alevizos2017event}. And the events stream $s$ is considered as the input word of the DFA. 

Furthermore, if $\forall q \in Q$ of a DFA the all $\delta(q)^{-m}$ are sets of cardinality 1, then the DFA is called \textit{m-unambiguous}. ~\citet{nuel_pattern_2008} proposed a procedure to transform any DFA to an \textit{m-unambiguous} DFA, which is achieved by incrementally duplicate all states have m-ambiguity (i.e., $\vert\delta(q)^{-m}\vert > 1$).   Figure ~\ref{fig:dfa_adc} shows an associated DFA of a sequential pattern $\mathcal{P}=a ; d ; c$ over an alphabet $\Sigma=\{a,b,c,d\}$. 


\input{dfa_figure}

%(note that the DFA has no dead states since we need to handle streams and not strings).

\item Assume that the input events stream $s=\langle e_1,e_3,...,e_t,...\rangle$ is a $m$-order Markov sequence, where $m \geq 1$.  Given a constructed \textit{m-unambiguous} DFA for the pattern $\mathcal{P}$, ~\citet{nuel_pattern_2008} showed that the sequence of states of the DFA that generated by consuming the input events stream $s$ is a first-order Markov chain, which is represented by $\langle q_{0},q_{1},...,q_{t},...\rangle$, where $q_{0}=s$ and $q_{t}=\delta(q_{t-1},e_{t})$. We denote by \pmcmr  the derived Markov chain associated with a pattern $\mathcal{P}$ that is called a Pattern Markov Chain (PMC) of order $m$ \cite{nuel_pattern_2008}. In other words, we perform a direct mapping of the states of the DFA to states of a Markov chain and the transitions of the DFA to transitions of the Markov chain.Thus, the terms \textit{m-unambiguous} DFA of a pattern and the corresponding \pmcmr  we will be used interchangeably. 

\par Furthermore, the \pmcmr is characterized by $\vert Q \vert \times \vert Q \vert$ transition probability matrix $\Pi$ where $Q$ is again the set of states of the  \textit{m-unambiguous} DFA. Figure ~\ref{fig:dfa_adc} depicts the PMC of order 1 for the generated DFA of Figure ~\ref{fig:mc_adc}.

%\par The next step is to derive a Markov chain that will be able to provide a probabilistic description of the DFA's run-time behavior.
%\par Towards this goal, we use Pattern Markov Chains, as was proposed in \cite{nuel_pattern_2008}.
%, it can be shown that there is a direct mapping of the states of the DFA to states of a Markov chain and the transitions of the DFA to transitions of the Markov chain.
%\par The transition probabilities of the Markov chain are the occurrence probabilities of the various event types.
%On the other hand, if the occurrence probabilities of the events are dependent on some of the previous events  seen in the stream (i.e., the stream is generated by an $m^{th}$ order Markov process), we might need to perform a more complex transformation 
%(see \cite{nuel_pattern_2008} for details)
%in order to obtain a ``proper'' Markov chain.
%The transition probabilities are then conditional probabilities on the event types.
%In any case,
%we call such a derived Markov chain a Pattern Markov Chain (PMC) of order $m$
%and denote by \pmcmr , where $\mathcal{P}$ is the initial pattern and $m$ the assumed order.
 
\end{itemize}


\input{dfa_mc_figure}
%\end{comment}

\subsubsection*{PMC Prediction Model}
\label{sec:pmc_prediction}

~\citet{alevizos2017event} proposed to use the constructed \pmcmr to build a probabilistic prediction model that describes the DFA's run-time behavior. The method is based on calculating the \textit{waiting-time} distributions. Given a specific state of the \pmcmr, a \textit{waiting-time} distribution provides the probability of reaching a set of absorbing states in $n$ transition from current state. So by mapping the final states of the DFA to absorbing states of the \pmcmr by adding self-loops with probabilities equal to $1.0$. Therefore, we can calculate the probability of reaching a final state in $n$ transitions,  which means predicting a full match of the defined pattern $\mathcal{P}$.

\par We denote by $W_{\mathcal{P}}(q)$  the waiting-time random variable that represents the
number of transitions from a current state $q$ of DFA to reach a final state \cite{alevizos2017event}, where it also represents the expected number of future events from the current time event to  a full match of the pattern $\mathcal{P}$, which is given by 

\begin{equation*}
W_{\mathcal{P}}(q)=inf\{n: q_{0},q_{1},...,q_{n}, q_{0}=q, q \in Q \backslash F, q_{n} \in F\}
\end{equation*}

However, the \textit{waiting-time} distribution of the $W_{\mathcal{P}}(q)$ random variable can be computed based on the transition probability matrix $\Pi$ of the \pmcmr, where it has $h$ non-final states and $d$ final states (absorbing states) \cite{alevizos2017event}, then distribution is calculated by the following equation 

\begin{equation*}
P(W_{\mathcal{P}}(q)=n)=\boldsymbol{\xi_{q}}\boldsymbol{N}^{n-1}(\boldsymbol{I}-\boldsymbol{N})\boldsymbol{1}
\end{equation*}
where $\boldsymbol{N}$ is $h \times h$ matrix that obtained by re-arranging the transition matrix $\Pi$ to include transitions between the non-final states of the DFA, $\boldsymbol{I}$ is an identity matrix of size $d \times d$, and  $\boldsymbol{1}$ is $h \times 1$ vector of ones. The $\boldsymbol{\xi_{q}}$ is $1 \times h$ row of elements that contains zeros except $1.0$ in the cell corresponding to $q$. 
\par Finally, the model provides the prediction reports in the form of intervals i.e.,  $I=(\mathit{start},\mathit{end})$. Which means that the DFA is expected to reach a final state  after future transitions ( number of events $n$) between $\mathit{start}$ and $\mathit{end}$ with probability $P(I)$ at least some constant threshold $\theta_{p}$ that defined by the user, given by: 
 given by:
\begin{equation*}
P(I)=\sum_{n \in I}{P(W_{\mathcal{P}}(q)=n)}\ where\  P(I) \geq \theta_{p} 
\end{equation*}
where $P(I)$ equals the sum of probabilities of all number of future events $n$ that fall within $I$ ($start\leq n\leq end$). Furthermore, the length of the intervals ($spread(I) = end - start$)  can be restricted to not be greater than a maximum spread threshold $\theta_{s}$.  

\begin{equation*}
spread(I)\leq \theta_{s}
\end{equation*}

These intervals are estimated by a single-pass algorithm that scans a waiting-time distribution and finds the smallest (in terms of length) interval that exceeds the $\theta_{p}$ and has a spread  not greater that $\theta_{s}$. Figure \ref{fig:wtdfas} shows an example of how the predictions intervals are produced, where Figure \ref{fig:wt1} shows the \textit{waiting-time} distributions for all non-final states of the DFA presented in Figure ~\ref{fig:dfa_adc}, and the generated intervals are  depicted in Figure ~\ref{fig:predictionsIntervals}.


\begin{figure}[!ht]
	\begin{centering}
		
		\subfloat[Waiting-time distribution.]{ 
			\includegraphics[width=.5\textwidth]{chapters/figures/wt.png}
			\label{fig:wt1}
		}
	
		\subfloat[Prediction intervals.]{ 
			\includegraphics[width=.5\textwidth]{chapters/figures/predictions.png}
			\label{fig:predictionsIntervals}
		}
		
		\caption{Example of computed prediction intervals for
			$\mathcal{P}=a ; d ; c$, $\Sigma=\{a,b,c,d\}$, $m=1$, $\theta_{p}=0.5\ and\ \theta_{s}=20$.}
		\label{fig:wtdfas}
	\end{centering}
\end{figure}

\par The proposed method assumes that the transition probability matrix $\Pi$ is available to build the prediction intervals. However, this is not true in the real-world applications.
Therefore, it is essential to learn the values of the \pmcmr's transition probability matrix in order apply this method. One common way, is to use the maximum-likelihood estimator to learn the transition probabilities as illustrated in Section ~\ref{sec:theoretical}. 

\par This model is performing the learning over an event stream $s$ that  usually requires a large amount of time until convergence to a sufficiently good model.  Where in the case of multiple event streams, a unique model associated with each stream is needed. Accordingly, we present in this work, a technique to share information among the \pmcmr predictors over multiple input event streams (i.e., distributed learning of the transition probability matrix).

\section{Pattern Prediction over Multiple Event Streams}

In this section, We extend the pattern prediction problem over a single event stream to the case of multiple and distributed input event streams, where there is an associated prediction model for each event stream. And We further present our proposed cooperative learning based approach by using a distributed online prediction protocol \cite{kamp2014communication} to synchronize the distributed prediction models in a communication-efficient manner. 


\subsection{Problem Formulation Extension}

\par In this section, we extend the problem of pattern prediction over a single event stream to consider the setting where there are multiple input event streams: 
Let $O = \{ o_1, ..., o_k\}$ be a set of \emph{$K$} objects/entities (e.g., moving objects), each of which is generating an event stream $s_i$, hence, we have a set of real-time input event streams $S = \{ s_1, ..., s_k\}$, where these streams are produced independently from the same distribution.


\par Again, let $\mathcal{P}$ be a user-defined pattern given in the form of regular expression, which is monitored in every stream $s_i \in S$. Then, we have a system consists of \emph{$K$} local predictor (learner) nodes $n_1,n_2...,n_k$, each of which receives an input event stream $s_i\in S$ that is associated with a single object $o_i \in O$.

\par  The goal is to provide online predictions about the completion of the pattern $\mathcal{P}$ within each stream $s_i$. Toward this goal, each node maintains a local prediction model $f_i$. Then for each new arriving event tuple  $e_t \in s_i$, the $f_i$ model provides an online prediction interval about the future full match of the pattern $\mathcal{P}$.

\par In other words, we have multiple running instances of an online prediction algorithm on distributed nodes for multiple input event streams. For example, massive streams of events that describe trajectories of moving vessels in the context of maritime surveillance, where there is one predictor node for each vessel's event stream.
  
  
  \par In this work, we employee the \pmcmr models on the distributed local predictor nodes, while these predictors can work in isolation with no communication with other local predictors, but this non-cooperative way leads to inefficiently in the terms of learning convergence and predictive performance among all predictors. Thus, in this work, we propose to use the distributed online prediction protocol \cite{kamp2014communication} to enable the communication among the local predictors to synchronize their models.     
%
%The defined pattern $\mathcal{P}$ is monitored over each event stream $s_i$  by a  predictor nodes  $n_i$  that maintains a local prediction model $f_i$, where there is one node for each vessel's event stream.  The prediction model $f_i$ gives the ability to provide an online predictions about when the pattern will be completed in the form of an expected number of future events before a full match does occur.

\subsection{The Proposed Method}
\label{sec:proposed_approach}
\par This work proposes a scalable and distributed prediction system for user-defined patterns over multiple massive input event streams. The system  uses the PMC forecasting method \cite{alevizos2017event} as the base prediction model, where there is a \pmcmr model associated with each input event stream $s_i$ on a predictor node $n_i$. And it employees the distributed online learning protocol \cite{kamp2014communication} to exchange information among the distributed predictors of the input event streams, which allows to synchronize the parameters of their prediction models, which are represented by the transitions probabilities matrices.

%
%Thus, the prediction model $f_i$ on a predictor node is represented by \pmcmr and its associated DFA.

\subsection*{Distributed Online Learning for Pattern Prediction Models}
\par In next, we describe the details of adapting the distributed online learning protocol \cite{kamp2014communication}  with the pattern prediction (\pmcmr) models. Where this protocol provides a communication-efficient dynamic synchronization scheme based on a periodic static scheme.




\par Algorithm~\ref{algonline:dol} presents the distributed online prediction protocol by dynamic model synchronization on both the predictor nodes and the coordinator. We refer to the PMC's transition matrix $\boldsymbol{\Pi}_i$ on predictor node $n_i$ by $w_i$. That is, when a predictor $n_i:\ i \in[k]$ observes an event $e_j$ it revises its internal model state (i.e., $f_i$) and provides a prediction report. Then it checks the local conditions  (batch size $b$ and local model divergence from a reference model $w_r$) to decide whether there is a need to synchronize its local model with the coordinator [or not].  $w_r$ is maintained in the predictor node as a copy of the last computed aggregated model $\hat{w}$ from the previous full synchronization step, which is shared between all local predictors/learners. By monitoring the local condition $\|w_i - w_r\|^2 > \Delta$ on all local predictors, we have a guarantee that if none of the local conditions is violated, the divergence (i.e., variance of local models $\delta(w)=\frac{1}{k} \sum_{j=1}^{k}\|w_i - \hat{w}\|^2$) does not exceed the threshold $\Delta$ \cite{kamp2014communication}. 

\par On the other hand, the coordinator receives the parameters of prediction models from the predictor nodes that requested for model synchronization (violation). Then it tries to keep incrementally querying other nodes for their local prediction models until reaching out all nodes, or the variance of the aggregated model $\hat{w}$ that is computed from the already received models less or equal than the divergence threshold  $\Delta$. Finally, the aggregated model $\hat{w}$ is sent back to the predictor nodes that sent their models after the violation or have been queried by the coordinator.

\begin{algorithm}[h]
	\caption{Communication-efficient Distributed Online Learning \cite{kamp2014communication}.} 
	\begin{algorithmic}[1] 
	
		\Statex \Indm  \textbf{Predictor} node $n_i$: at observing event $e_j$
		
		\Statex \Indp update the parameters of the local prediction model $w_i$ and provide a prediction interval $I$ \;
	 

		\Statex \If {$j\mod b = 0\ and\ \|w_i - w_r\|^2 > \Delta$}  
		\Statex send  $w_i$ to the Coordinator (violation) \;
		\Statex \Indm \textbf{Coordinator}:
		\Statex \Indp receive parameters of local models with violation 
		 $B=\{w_i\}_{i=1}^m$ \;
	
	
		\Statex \While{$|B| \neq k $ and $\frac{1}{|B|} \ \sum_{w_i\in  \Pi}\|w_i - \hat{w}\|^2 > \Delta$}{
			
			 \Statex  \hspace{\algorithmicindent} add other nodes that have not reported violation for \Statex \hspace{\algorithmicindent} their models $ B \gets \{w_l : f_l \notin B\ and\ l \in [k]\}$    \;
			\Statex  \hspace{\algorithmicindent} receive models from nodes in $B$\;
	}
        \Statex
		\Statex compute a new global model $\hat{w}$ \;
		\Statex send $\hat{w}$ to all the predictors in $B$ and set $f_{1}\dots f_{m}=\hat{w} $\; 
		\Statex \If {$|B| = k$}{
		\Statex  \hspace{\algorithmicindent} set a new reference model $w_r	\gets \hat{w}$ \; }
	
	\end{algorithmic}
	\label{algonline:dol}
\end{algorithm}


\par  We use this protocol for the pattern prediction models, which are internally based on the \pmcmr. This allows the distributed \pmcmr predictors for multiple event streams to synchronize their models (i.e., the transition probability matrix of each predictor) within the system in a communication-efficient way. 


\subsection*{Learning a Global Transition Probability Matrix}
\par We propose a \textit{synchronization operation} for the transition probability matrices ($w_i=\boldsymbol{\Pi}_i :i \in[k]$) of the $k$ distributed \pmcmr predictors. The operation is based on distributing the maximum-likelihood estimation \cite{anderson1957statistical} for the transition probabilities of the \pmcmr models described by: 
\begin{equation}
\label{eq:dis_pi_estim}
\hat{\pi}_{i,j}=\frac{\sum_{k \in K} n_{k,i,j}}{\sum_{k \in K} \sum_{l \in L} n_{k,i,l}}
\end{equation}

Where $\hat{\Pi}$ is the global transition probability matrix that will be shared among all \pmcmr predictors. 
\par Moreover, we measure the divergence of the local models from the reference model  $\|w_k - w_r\|^2$ by calculating the sum of square difference between the transition probabilities  $\boldsymbol{\Pi}_i$ and  $\boldsymbol{\Pi}_r$:
\begin{equation*}
\label{eq:dis_pi_varinace}
\|w_k - w_r\|^2=\sum_{i,j} (\hat{\pi}_k{i,j} -\hat{\pi}_r{i,j})^2
\end{equation*}
%ADD something about modes%



\input{chapters/theoretical}
