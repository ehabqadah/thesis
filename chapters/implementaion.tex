

\chapter{System Overview}
\label{chapter:overview}


\par In this chapter, we present the architecture of the proposed system for pattern prediction over multiple input event streams in a scalable distributed setting. To build a scalable and distributed system, we implement the system on top of Apache Flink engine for distributed and large-scale stream processing. We also use Apache Kafka for the distributed communication and to ingest and emit the input/output data streams. In what follows we describe the building blocks of the proposed system and the important aspects of the implementation.

%ADD more details and interfacse structure%
%CHECK Towards Flexible Event Processing in Distributed Data Streams%
%SEE delevriable%
\section{System Architecture}
\label{sec:architecture}
The input to our system is an aggregated stream of events coming from a large number of  objects, which is continuously collected and fed into the system. In practice, the aggregated input events stream is composed of multiple event streams (partitions) from a set of objects. Our system allows the users to register a pattern $\mathcal{P}$ to be monitored over each event stream. The output stream consists of original input events along with  the prediction intervals of the full matches of monitored pattern $\mathcal{P}$, which are displayed to the end users. Figure~\ref{fig:architecture} presents an overview of our system architecture and its main components.      


\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{chapters/figures/system_v2.png}
	
	\caption{System architecture overview.}
	\label{fig:architecture}
\end{figure}

The system is composed of three main processing elements:   
\begin{itemize}
	
	\item The pre-processing operators: Operators receive the input event stream and perform filtering and ordering operations, before partitioning the input event stream to multiple event streams based on the associated object. 
	\item The predictor nodes (learners): Each predictor is responsible for maintaining a prediction model for an input event stream. Each prediction node is configured to handle an event stream from the same  object, in order to provide online predictions for the user-defined pattern $\mathcal{P}$.  
	\item The coordinator node:  A central node communicates through Kafka stream channels with the predictors to realize the distributed online learning protocol. It builds a global prediction model, based on the received local models, and then shares it among the predictors.
\end{itemize}

\par Our distributed system consists of multiple pre-processing operators, prediction nodes, and a central coordinator node. All units run in parallel and are arranged as a data processing pipeline, depicted in Figure ~\ref{fig:architecture}. We leverage Apache Kafka as a messaging platform to ingest the input event streams and to publish the resulting streams. Also, it is used as the communication channel between the predictor nodes and the coordinator. Apache Flink is employed to execute the system's distributed processing units over the input event streams, namely, the pre-processing operators,  the prediction units, and the coordinator node. Our system architecture can be modeled as a logical network of processing nodes, organized in the form of a DAG, inspired by the Flink runtime dataflow programs \cite{carbone2015apache}. 

\section{Implementation Details}
\label{sec:impl}
In this section, we describe in detail the implementation \footnote{The source code can be found here: \url{https://github.com/ehabqadah/distributed_online_learning_for_large-scale_pattern_prediction}} of our system. It has been implemented on top of Apache Flink and Apache Kafka frameworks. Each of the three sub-modules, described in Section~\ref{sec:architecture}, have been implemented as Flink operations over the input events stream. 

\textbf{Pre-processing and Prediction Operators.} Listing ~\ref{algonline:flink1} shows how the main workflow of the system is implemented as Flink data flow program.

The system ingests the input events stream from a Kafka cluster that is mapped to a \textit{DataStream} of events, which is then processed by an \textit{EventTuplesMapper} to create tuples of \textit{(id, event)}, where the \textit{id} is associated to the identifier of the moving object. To handle events  coming in out of order in a certain margin, the stream of event tuples  is processed by a \textit{TimestampAssigner}, it assigns the timestamps for the input events based on the extracted creation time. Afterwards,  an ordered stream of event tuples is generated using a process function \textit{EventSorter}.
\begin{center}
	\centering
	\begin{lstlisting}[caption={Flink pipeline for local predictors workflow},label={algonline:flink1},frame=single]
	DataStream<Event> eventsStream = env.addSource(kafkaConsumer);	
	// Create event tuples (id,event) and assign time stamp 
	DataStream<Tuple2<String,Event>> eventTuplesStream =
	inputEventsStream.map(new EventTuplesMapper())
	.assignTimestampsAndWatermarks(new EventTimeAssigner());	
	// Create the ordered keyed stream 
	 keyedEventsStream = eventsStream.keyBy(0).process(new EventSorter()).keyBy(0);	
	//Initialize the predictor node 
	LocalPredictorNode predictorNode =new LocalPredictorNode<Event>(P);
	// Process the  keyedEventsStream by the predictor 
	DataStream<Event> processedEventsStream =
	keyedEventsStream.map(predictorNode);
	\end{lstlisting}
\end{center}
\par The ordered stream is then transformed to a \textit{keyedEventsStream} by partitioning it, based on the ids values, using a \textit{keyBy} operation. A local \textit{predictor} node in a distributed environment is represented by a \textit{map} function over the \textit{keyedEventsStream}. Each parallel instance of the map operator (predictor) always processes all events of the same moving object (i.e., equivalent id), and maintains a bounded prediction model (i.e., \pmcmr\  predictor) using the Flink's Keyed State  \footnote{{Keyed State in Flink: \url https://ci.apache.org/projects/flink/flink-docs-release-1.3/dev/stream/state.html\#kayed-state}}.  The output streams of the moving objects from the parallel instances of the predictor map functions are sent to a new Kafka stream (i.e., same topic name).  They then can be processed by other components like visualization or users notifier.


\par Moreover, the implementation of the \textit{predictor} map function includes the communication  with \textit{coordinator} using Kafka streams.
Figure~\ref{fig:class_diagram} shows the general class hierarchy of the predictor node. At the beginning of the execution,  each predictor instance sends a registration request to the coordinator. Also at the run-time,  it sends  its local prediction model as synchronization request,  or as a response for a resolution request from the coordinator. These coordination messages are published into different Kafka topics as depicted in Table~\ref{tab:messagesToTopics}. 
 
 
 \begin{figure}[H]
 	\centering
 	\includegraphics[width=\textwidth,height=\linewidth]{chapters/figures/predictor_diagram.png}
 	
 	\caption{Predictor node class hierarchy.}
 	\label{fig:class_diagram}
 \end{figure}

 
\begin{center}
\centering
\begin{table}[h]
	\caption{Messages to Kafka topics mapping.}
	\label{tab:messagesToTopics}
	\begin{tabular}{p{8cm}l}
		\toprule
		Message &Kafka Topic\\
		\midrule
		\parbox[t]{8cm}{\textit{RegisterNode}, \textit{RequestSync},  and \textit{ResolutionResponse} } & LocalToCoordinatorTopicId\\ \\
		
			  \parbox[t]{8cm}{\textit{CoordinatorSync}, \textit{UpdateReference}, and \\ \textit{RequestResolution}} & CoordinatorToLocalTopicId\\
		\bottomrule
	\end{tabular}
\end{table}

\end{center}

\textbf{Coordinator.} Listing~\ref{algonline:flink2} presents the workflow of the coordinator node that manages the distributed online learning protocol operations, which is implemented as Flink program. The coordinator receives messages from the local predictors through a Kafka Stream of a topic named \textit{LocalToCoordinatorTopicId}. It is implemented as a single \textit{flatMap} function over the messages stream, by setting the \textit{parallelism} level of the Flink program to \textit{1}. Increasing the parallelism will scale up the number of parallel coordinator instances, for example, in order to handle different groupings of the input event streams. The map operator of the coordinator  handles three message types from the predictors: \begin{enumerate}[]
	\item \textbf{RegisterNode} that contains  a registration request for a new predictor node.
	\item \textbf{RequestSync} to receive a local model after violation.
	\item \textbf{ResolutionResponse} to receive a resolution response from a local predictor node.  
\end{enumerate}  

\begin{center}
	\centering
\begin{lstlisting}[caption={The coordinator Flink program.},label={algonline:flink2},frame=single]
	// Initialize the Flink environment	 
	 StreamExecutionEnvironment env =
	 new StreamExecutionEnvBuilder().setParallelism(1).
	 setStateBackend(cehkPointsPath).build();	 
	// Read messages from local predictors
	DataStream<Tuple2<String, CoordinationMessage>> messages =
	env.addSource(initKafkaConsumer()).map(new CoordinationMessagesTupleMapper());	
	// Initialize the coordinator node
	CoordinatorNode coordinatorNode = new CoordinatorNode(patternName);	
	// Process the messages stream by the coordinator
	DataStream<CoordinationMessage> messagesToPredictors =
	messages.keyBy(0).flatMap(coordinatorNode);	
	// Write the coordination messages for predictors to kafka
	messagesToPredictors.addSink(getKafkaProducer(outputStreamTopic));

\end{lstlisting}
\end{center}

 On the other hand, it sends \textbf{CoordinatorSync} messages for all predictors after creating a new global prediction model, or \textit{UpdateReference} to set the reference model. It also send  \textbf{RequestResolution} messages to a ask the local predictors for their prediction models. Figure~\ref{fig:coord_class_diagram} depicts the  class hierarchy of the coordinator node.
 
 \begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth,height=\linewidth]{chapters/figures/coordinator_diagram.png}
	
	\caption{Coordinator node class hierarchy.}
	\label{fig:coord_class_diagram}
\end{figure}