

\subsection{Pattern Prediction Over Event Streams}

\par Several approaches have been proposed to formalize the task of event patterns prediction over time-evolving data streams.  One common way to formalize this task is to assume that the stream is a time-series of numerical values, and the goal is to predict at each time point $t$ the future observation at some future points $t+1$, $t+2$, etc., (or even the output of some function of future values)~\cite{montgomery_introduction_2015}. 


%The task of forecasting over time-evolving streams of data can be formulated in various ways and with varying assumptions.
%One common way to formalize this task is to assume that the stream is a time-series of numerical values, and the goal is to forecast at each time point $n$ the values at some future points $n+1$, $n+2$, etc., (or even the output of some function of future values). 
% This is the task of time-series forecasting ~\citet{montgomery_introduction_2015}.

Another way to formalize the prediction task is to view streams as sequences of events,
i.e., tuples with multiple, possibly categorical, attributes, such as \textit{id}, \textit{event type}, \textit{timestamp} etc., and the goal is to predict future events or  patterns of events. In this thesis, we focus on the latter definition of forecasting (event patterns prediction).  

\par Another line of research relates to the task of event patterns prediction is the field of temporal pattern mining where events are defined as 2-tuples of the form \((\mathit{EventType}, \mathit{Timestamp})\). The goal is to extract patterns of events in the form either of association rules \cite{agrawal_mining_1993} or frequent episode rules \cite{mannila_discovery_1997}. These methods have been extended in order to be able to learn not only rules for detecting event patterns but also rules for predicting events. For example, in \cite{vilalta_predicting_2002}, a variant of association rule mining is where the goal is to extract sets of event types that frequently lead to a rare, target event within a temporal window. 

\par In \citet{laxman_stream_2008}, the authors proposed a probabilistic model
for calculating the probability of the immediately next event in the stream. Which is achieved by using standard frequent episode discovery algorithms and combining them with Hidden Markov Models and mixture models. The framework of episode rules is employed in \cite{fahed_efficient_2014} as well. The output of the proposed algorithms is a set of predictive rules whose antecedent is minimal (in number of events) and temporally distant from the consequent.

\par In \cite{zhou_pattern_2015} a set of algorithms is proposed that target batch online mining of sequential patterns, without maintaining exact frequency counts. As the stream is consumed, the learned patterns can be used to test whether a prefix matches the last events seen in the stream, indicating a possibility of occurrence for events that belong to the suffix of the rule.

% add more details about the cep
\par Event pattern prediction has also attracted some attention from the field of complex cvent processing (CEP), where the CEP system consumes a stream of low-level events, and the target is to detect patterns of events (composite events), defined using pattern-based languages that provide logic, sequence, and iteration operators such as SQl-like languages \cite{Cugola:2012:PFI:2187671.2187677}. One such early approach is presented in \cite{muthusamy_predictive_2010}, which is based on converting the complex event patterns to automata, and subsequently, Markov chains are used in order to estimate when a pattern is expected to be fully matched. Moreover, ~\citet{alevizos2017event} have recently presented a similar approach, where again automata and Markov chains are employed in order to provide (future) time intervals during which a match is expected with a probability above a confidence threshold. In this thesis, we leverage this method as the base prediction model for each input event stream (see Section ~\ref{sec:Event-Forecasting-PMC}). 